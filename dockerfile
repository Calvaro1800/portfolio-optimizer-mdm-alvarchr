# ğŸ“¦ Ã‰tape 1 : Image de base lÃ©gÃ¨re et compatible avec llama-cpp-python
FROM python:3.12-slim

# ğŸ“ Ã‰tape 2 : RÃ©pertoire de travail
WORKDIR /app

# ğŸ“„ Ã‰tape 3 : Copier tous les fichiers dans le conteneur
COPY . .

# âš™ï¸ Ã‰tape 4 : Installer les dÃ©pendances systÃ¨me nÃ©cessaires
RUN apt-get update && \
    apt-get install -y \
    gcc \
    g++ \
    cmake \
    make \
    libffi-dev \
    libsasl2-dev \
    libssl-dev \
    libxml2-dev \
    libxslt1-dev \
    zlib1g-dev \
    build-essential \
    python3-dev \
    git \
    curl && \
    rm -rf /var/lib/apt/lists/*

# ğŸ”§ Ã‰tape 5 : Mise Ã  jour de pip
RUN pip install --upgrade pip

# ğŸ“œ Ã‰tape 6 : Installer les dÃ©pendances Python
RUN pip install --no-cache-dir -r requirements.txt

# ğŸ” Ã‰tape 7 : Charger les variables dâ€™environnement depuis .env automatiquement
ENV FLASK_APP=app.py
ENV FLASK_ENV=production
ENV GGUF_MODEL_PATH=/app/models/llama-model.gguf

# âœ… Option : copie explicite du modÃ¨le si tu le montes Ã  lâ€™extÃ©rieur
# COPY models/llama-model.gguf /app/models/llama-model.gguf

# ğŸŒ Ã‰tape 8 : Exposer le port Flask
EXPOSE 5000

# ğŸš€ Ã‰tape 9 : Lancement de lâ€™app Flask
CMD ["flask", "run", "--host=0.0.0.0", "--port=5000"]
